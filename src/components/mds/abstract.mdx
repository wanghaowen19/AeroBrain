# Abstract

Unmanned aerial vehicles (UAVs) have become pivotal in fields such as search and rescue, surveillance, and logistics, necessitating advancements in intelligent navigation algorithms. In this paper, we propose AeroBrain, a novel multimodal UAV navigation framework that integrates Multimodal Large Models (MLMs) for high-level decision-making with Deep Reinforcement Learning (DRL) for low-level motion control. AeroBrain employs a Sensing Large Language Model (LLM) to extract task-relevant targets from semantic maps and a Planning MLM to determine optimal movement directions based on multimodal cues. A Soft Actor-Critic (SAC) algorithm further ensures adaptive and efficient path planning, enhancing UAV responsiveness. Extensive experiments in simulated environments demonstrate that AeroBrain significantly outperforms existing methods in trajectory efficiency, navigation accuracy, and success rate, while maintaining robust adaptability to complex, dynamic scenarios. The proposed framework advances UAV autonomy by bridging human-intuitive instruction interpretation with real-time navigation and control, offering a promising approach for intelligent UAV deployment in real-world applications.