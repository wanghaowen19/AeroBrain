# Abstract

Unmanned aerial vehicles (UAVs) have become pivotal in fields such as search and rescue, surveillance, and logistics, necessitating advancements in intelligent navigation algorithms. This paper introduces AeroBrain, an autonomous UAV navigation system that integrates multimodal large models (MLMs) and deep reinforcement learning (DRL) to enhance natural language-driven object search tasks. The system leverages MLMs for high-level decision-making, interpreting human instructions and environmental data to optimize navigation strategies. Concurrently, a Soft Actor-Critic (SAC) algorithm ensures responsive and efficient path planning, enabling UAVs to navigate complex, dynamic environments. Experiments conducted in a simulated factory environment using the AirSim platform demonstrate AeroBrain's superior performance in terms of trajectory efficiency, navigation accuracy, and success rate compared to existing methods. Additionally, we explore the system's adaptability across different large models and its robustness in varying path planning scenarios. The results validate AeroBrain's effectiveness in achieving precise, adaptive, and efficient UAV navigation, highlighting its potential for broader applications in autonomous systems.
